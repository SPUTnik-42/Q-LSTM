# Analysis of Quantum-LSTM Variants for Time Series Forecasting
## Abstract: 
This study explores the use of different Quantum Long-Short-Term Memory models on time series data. We investigate a suite of various models including Quantum Long Short-Term Memory (qLSTM), Quantum Gated Recurrent Unit (qGRU), Quantum Long Short-Term Memory with Dual-stage Attention, Quantum Bidirectional Long Short-Term Memory, and stacked variants, Furthermore, we put forward a hybrid ARIMA-Quantum LSTM (ARIMA-qLSTM) model, in order to capture both the linear and non-linear patterns in the data. These models are put together by utilising various parameterized quantum circuits, mimicking the architecture of their classical counterparts. The results indicate that the quantum models outperform most of the classical ones. This work highlights the importance of Quantum Neural Networks in advancing time series forecasting and provides a significant step forward in leveraging quantum computing for practical machine learning tasks.

### Keywords: Quantum LSTM, Quantum Time Series Forecasting, Quantum Machine Learning, Variational Quantum Circuits

