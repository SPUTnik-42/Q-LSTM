{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy.random import default_rng\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2f9dcf4030>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "rng = default_rng(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data, window_size, predict_size):\n",
    "    scaler1 = StandardScaler()\n",
    "    scaler2 = StandardScaler()\n",
    "    d_y = scaler1.fit_transform(data.iloc[:,-1:])\n",
    "    data = scaler2.fit_transform(data.iloc[:,:4])\n",
    "\n",
    "    data_in = []\n",
    "    data_out = []\n",
    "    # range(window_size,len(data)-predict_size+1) range(data.shape[0] - window_size - predict_size + 1)\n",
    "    for i in range(window_size,len(data)-predict_size+1):\n",
    "        data_in.append(data[i-window_size:i,0:data.shape[0]])\n",
    "        data_out.append(d_y[i + predict_size - 1:i + predict_size,0])\n",
    "\n",
    "    data_in = np.array(data_in)\n",
    "    data_out = np.array(data_out)\n",
    "\n",
    "    data_process = {'datain': data_in, 'dataout': data_out}\n",
    "\n",
    "    return data_process, scaler1 , scaler2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(src='./Data/city_hour.csv',city='Delhi',datetime='2016-01-01 00:00:00', date_column = 'Datetime', datemore = None,\n",
    "                    imp_columns=['PM2.5','PM10','CO','AQI'], target='AQI'):\n",
    "    dfi = pd.read_csv(src)\n",
    "    dfi.dropna()\n",
    "    if city is not None:\n",
    "        df = dfi.loc[ dfi['City'] == city]\n",
    "    if datemore is None:\n",
    "        df = df.loc[df[date_column] < datetime]\n",
    "    else: \n",
    "        df = df.loc[df[date_column] > datetime]\n",
    "    for i in list(df.columns):\n",
    "        if i not in imp_columns:\n",
    "            df = df.drop(i)\n",
    "    df = df.reset_index()\n",
    "    df['nxt_target'] = df[target].shift(-1)\n",
    "    df['nxt_target'][len(df)-1] = df['nxt_target'][len(df)-2]\n",
    "\n",
    "    size = int(len(df) * 0.8)\n",
    "\n",
    "    train = df.iloc[:size].copy()\n",
    "    test = df.iloc[size:].copy()\n",
    "    \n",
    "    features_size = 4\n",
    "    window_size = 10\n",
    "    predict_size = 1\n",
    "\n",
    "    train_processed, train_target_scalar, train_scaler = data_process(train, window_size, predict_size)\n",
    "    X_train, y_train = train_processed['datain'], train_processed['dataout']\n",
    "\n",
    "    test_processed, test_target_scalar, test_scaler = data_process(test, window_size, predict_size)\n",
    "    X_test, y_test = test_processed['datain'], test_processed['dataout']\n",
    "\n",
    "    X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "    X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "\n",
    "    y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "    y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, train_target_scalar, train_scaler, test_target_scalar, test_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader, model):\n",
    "    \"\"\"Just like `test_loop` function but keep track of the outputs instead of the loss\n",
    "    function.\n",
    "    \"\"\"\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _ in data_loader:\n",
    "            y_star = model(X)\n",
    "            output = torch.cat((output, y_star), 0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runmodel(modelQ, trainDataloader):\n",
    "    histQ = np.zeros(num_epochs)\n",
    "    histQacc = np.zeros(num_epochs)\n",
    "    count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_Q = []\n",
    "        rmse_q = []\n",
    "        correct = 0\n",
    "        batches = 0\n",
    "        for (x, y) in trainDataloader:\n",
    "            modelQ.zero_grad()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = modelQ(x)\n",
    "            label = y.squeeze(1)\n",
    "            lossQ = criterion(output, label)\n",
    "            lossQ.backward()\n",
    "            optimizerQ.step()\n",
    "            loss_Q.append(lossQ.item())\n",
    "        histQ[epoch] = np.sum(loss_Q)\n",
    "        print(f'[{epoch+1}/{num_epochs}]  LossQ:{np.sum(loss_Q)}')\n",
    "\n",
    "    print('\\n\\n\\n')\n",
    "\n",
    "    #np.savetxt('./SavedModels/Loss/stacked_qgru.txt',histQ)\n",
    "    plt.figure(figsize = (12, 6))\n",
    "    plt.plot(histQ, color = 'blue', label = 'Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(loc = 'upper right')\n",
    "\n",
    "    print('\\n\\n\\n')\n",
    "\n",
    "    pred_y_train = modelQ(X_train)\n",
    "    pred_y_test = modelQ(X_test)\n",
    "    pred_y_train = pred_y_train.reshape(-1, 1)\n",
    "    pred_y_test = pred_y_test.reshape(-1, 1)\n",
    "    y_train_true = train_target_scalar.inverse_transform(y_train)\n",
    "    y_train_pred = train_target_scalar.inverse_transform(pred_y_train.cpu().detach().numpy())\n",
    "    y_test_true = test_target_scalar.inverse_transform(y_test)\n",
    "    y_test_pred = test_target_scalar.inverse_transform(pred_y_test.cpu().detach().numpy())\n",
    "    #np.savetxt('./SavedModels/Train/stacked_qgru.txt',y_train_pred)\n",
    "    #np.savetxt('./SavedModels/Test/stacked_qgru.txt',y_test_pred)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20, 13))\n",
    "    plt.plot(y_train_true, color = 'red', label = 'Acutal')\n",
    "    plt.plot(y_train_pred, color = 'blue', label = 'Predict')\n",
    "    plt.title('Prediction comparison')\n",
    "    plt.ylabel('Target')\n",
    "    plt.xlabel('Days')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    MSE = mean_squared_error(y_train_true, y_train_pred)\n",
    "    RMSE = math.sqrt(MSE)\n",
    "    print(f'Training dataset RMSE:{RMSE}')\n",
    "\n",
    "    print('\\n\\n\\n')\n",
    "\n",
    "    plt.figure(figsize=(20, 13))\n",
    "    plt.plot(y_test_true, color = 'red', label = 'Acutal')\n",
    "    plt.plot(y_test_pred, color = 'blue', label = 'Predict')\n",
    "    plt.title('QLSTM prediction comparison')\n",
    "    plt.ylabel('AQI')\n",
    "    plt.xlabel('Days')\n",
    "    plt.legend(loc = 'upper right')\n",
    "\n",
    "    MSE = mean_squared_error(y_test_true, y_test_pred)\n",
    "    RMSE = math.sqrt(MSE)\n",
    "    print(f'Training dataset RMSE:{RMSE}')\n",
    "    #torch.save(modelQ.state_dict(),'./SavedModels/AQI/stacked_QGRU_aqi_sd')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
